{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Solving an Ordinary Differential Equation in Python\n",
    "In this notebook, we numerically solve the following SIS model using Python. \n",
    "\\begin{align}\n",
    "\\frac{dS}{dt}&=-\\beta S I + \\alpha I\\\\\n",
    "\\frac{dI}{dt}&=\\beta S I - \\alpha  I\\\\\n",
    "\\end{align}\n",
    "with the initial conditions $S(0)=S_0,~I(0)=I_0$.\n",
    "\n",
    "\n",
    "Later, you will add some additional cells to this notebook to numerically solve the following SIR model.\n",
    "\\begin{align}\n",
    "\\frac{dS}{dt}&=-\\beta S I \\\\\n",
    "\\frac{dI}{dt}&=\\beta S I - \\alpha  I\\\\\n",
    "\\frac{dR}{dt}&= \\alpha I \n",
    "\\end{align}\n",
    "with the initial conditions $S(0)=S_0,~I(0)=I_0,~R(0)=R_0$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the ODE numerically and plot its solutions, we need to load to Python modules.  We do this using 'import'. When we write, for example, 'import numpy as np', this means we are importing the module called 'numpy', but we will be able to access its functions, etc., using the shorthand 'np'.  For example, if I want to create a numpy array, I can write np.array instead of numpy.array.\n",
    "\n",
    "*Task 1: Look up the following modules to get an idea for what they will be used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sm\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# enable pretty printing of equations\n",
    "sm.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a function that solves our ODE for a given set of parameters.  In the following cell, we define a function that computes the derivatives dS/dt and dI/dt that define the SIR model. The Python function 'def' is used to define your own functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model equations in function dydt.  \n",
    "# It returns, as an array, the values of the RHS of the ODE at (t,y).\n",
    "def dydt(t, y, par):\n",
    "                \n",
    "    alpha = par[0]\n",
    "    beta  = par[1]\n",
    "\n",
    "    S = y[0]\n",
    "    I = y[1]\n",
    "    R = y[2]\n",
    "    \n",
    "    dS =  -beta*S*I \n",
    "    dI = beta*S*I - alpha*I\n",
    "    dR = alpha*I\n",
    "    \n",
    "    return np.array([dS,dI,dR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we define a function 'SolveModel' that numerically solves the model.\n",
    "The inputs to this function are:\n",
    "1. array of parameter values, par.\n",
    "2. range over which to compute the solution, tspan.\n",
    "3. array of intial conditions, init_cond\n",
    "4. array of timepoints at which to output the solution.\n",
    "\n",
    "The function returns the solution to the ODE, which is numerically computed using the function 'solve_ivp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SolveModel(par,tspan,init_cond,t_eval):\n",
    "    \n",
    "    ode_soln = solve_ivp(dydt,\n",
    "                         tspan,\n",
    "                         init_cond,\n",
    "                         t_eval = t_eval,\n",
    "                         args = (par,))\n",
    "    return ode_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function solve_ivp in module scipy.integrate._ivp.ivp:\n",
      "\n",
      "solve_ivp(fun, t_span, y0, method='RK45', t_eval=None, dense_output=False, events=None, vectorized=False, **options)\n",
      "    Solve an initial value problem for a system of ODEs.\n",
      "    \n",
      "    This function numerically integrates a system of ordinary differential\n",
      "    equations given an initial value::\n",
      "    \n",
      "        dy / dt = f(t, y)\n",
      "        y(t0) = y0\n",
      "    \n",
      "    Here t is a one-dimensional independent variable (time), y(t) is an\n",
      "    n-dimensional vector-valued function (state), and an n-dimensional\n",
      "    vector-valued function f(t, y) determines the differential equations.\n",
      "    The goal is to find y(t) approximately satisfying the differential\n",
      "    equations, given an initial value y(t0)=y0.\n",
      "    \n",
      "    Some of the solvers support integration in the complex domain, but note that\n",
      "    for stiff ODE solvers, the right-hand side must be complex-differentiable\n",
      "    (satisfy Cauchy-Riemann equations [11]_). To solve a problem in the complex\n",
      "    domain, pass y0 with a complex data type. Another option is always to\n",
      "    rewrite your problem for real and imaginary parts separately.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        Right-hand side of the system. The calling signature is ``fun(t, y)``.\n",
      "        Here `t` is a scalar, and there are two options for the ndarray `y`:\n",
      "        It can either have shape (n,); then `fun` must return array_like with\n",
      "        shape (n,). Alternatively it can have shape (n, k); then `fun`\n",
      "        must return an array_like with shape (n, k), i.e. each column\n",
      "        corresponds to a single column in `y`. The choice between the two\n",
      "        options is determined by `vectorized` argument (see below). The\n",
      "        vectorized implementation allows a faster approximation of the Jacobian\n",
      "        by finite differences (required for stiff solvers).\n",
      "    t_span : 2-tuple of floats\n",
      "        Interval of integration (t0, tf). The solver starts with t=t0 and\n",
      "        integrates until it reaches t=tf.\n",
      "    y0 : array_like, shape (n,)\n",
      "        Initial state. For problems in the complex domain, pass `y0` with a\n",
      "        complex data type (even if the initial guess is purely real).\n",
      "    method : string or `OdeSolver`, optional\n",
      "        Integration method to use:\n",
      "    \n",
      "            * 'RK45' (default): Explicit Runge-Kutta method of order 5(4) [1]_.\n",
      "              The error is controlled assuming accuracy of the fourth-order\n",
      "              method, but steps are taken using the fifth-order accurate formula\n",
      "              (local extrapolation is done). A quartic interpolation polynomial\n",
      "              is used for the dense output [2]_. Can be applied in the complex domain.\n",
      "            * 'RK23': Explicit Runge-Kutta method of order 3(2) [3]_. The error\n",
      "              is controlled assuming accuracy of the second-order method, but\n",
      "              steps are taken using the third-order accurate formula (local\n",
      "              extrapolation is done). A cubic Hermite polynomial is used for the\n",
      "              dense output. Can be applied in the complex domain.\n",
      "            * 'Radau': Implicit Runge-Kutta method of the Radau IIA family of\n",
      "              order 5 [4]_. The error is controlled with a third-order accurate\n",
      "              embedded formula. A cubic polynomial which satisfies the\n",
      "              collocation conditions is used for the dense output.\n",
      "            * 'BDF': Implicit multi-step variable-order (1 to 5) method based\n",
      "              on a backward differentiation formula for the derivative\n",
      "              approximation [5]_. The implementation follows the one described\n",
      "              in [6]_. A quasi-constant step scheme is used and accuracy is\n",
      "              enhanced using the NDF modification. Can be applied in the complex\n",
      "              domain.\n",
      "            * 'LSODA': Adams/BDF method with automatic stiffness detection and\n",
      "              switching [7]_, [8]_. This is a wrapper of the Fortran solver\n",
      "              from ODEPACK.\n",
      "    \n",
      "        You should use the 'RK45' or 'RK23' method for non-stiff problems and\n",
      "        'Radau' or 'BDF' for stiff problems [9]_. If not sure, first try to run\n",
      "        'RK45'. If needs unusually many iterations, diverges, or fails, your\n",
      "        problem is likely to be stiff and you should use 'Radau' or 'BDF'.\n",
      "        'LSODA' can also be a good universal choice, but it might be somewhat\n",
      "        less convenient to work with as it wraps old Fortran code.\n",
      "    \n",
      "        You can also pass an arbitrary class derived from `OdeSolver` which\n",
      "        implements the solver.\n",
      "    dense_output : bool, optional\n",
      "        Whether to compute a continuous solution. Default is False.\n",
      "    t_eval : array_like or None, optional\n",
      "        Times at which to store the computed solution, must be sorted and lie\n",
      "        within `t_span`. If None (default), use points selected by the solver.\n",
      "    events : callable, or list of callables, optional\n",
      "        Events to track. If None (default), no events will be tracked.\n",
      "        Each event occurs at the zeros of a continuous function of time and\n",
      "        state. Each function must have the signature ``event(t, y)`` and return\n",
      "        a float. The solver will find an accurate value of `t` at which\n",
      "        ``event(t, y(t)) = 0`` using a root-finding algorithm. By default, all\n",
      "        zeros will be found. The solver looks for a sign change over each step,\n",
      "        so if multiple zero crossings occur within one step, events may be\n",
      "        missed. Additionally each `event` function might have the following\n",
      "        attributes:\n",
      "    \n",
      "            terminal: bool, optional\n",
      "                Whether to terminate integration if this event occurs.\n",
      "                Implicitly False if not assigned.\n",
      "            direction: float, optional\n",
      "                Direction of a zero crossing. If `direction` is positive,\n",
      "                `event` will only trigger when going from negative to positive,\n",
      "                and vice versa if `direction` is negative. If 0, then either\n",
      "                direction will trigger event. Implicitly 0 if not assigned.\n",
      "    \n",
      "        You can assign attributes like ``event.terminal = True`` to any\n",
      "        function in Python. \n",
      "    vectorized : bool, optional\n",
      "        Whether `fun` is implemented in a vectorized fashion. Default is False.\n",
      "    options\n",
      "        Options passed to a chosen solver. All options available for already\n",
      "        implemented solvers are listed below.\n",
      "    first_step : float or None, optional\n",
      "        Initial step size. Default is `None` which means that the algorithm\n",
      "        should choose.\n",
      "    max_step : float, optional\n",
      "        Maximum allowed step size. Default is np.inf, i.e. the step size is not\n",
      "        bounded and determined solely by the solver.\n",
      "    rtol, atol : float or array_like, optional\n",
      "        Relative and absolute tolerances. The solver keeps the local error\n",
      "        estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a\n",
      "        relative accuracy (number of correct digits). But if a component of `y`\n",
      "        is approximately below `atol`, the error only needs to fall within\n",
      "        the same `atol` threshold, and the number of correct digits is not\n",
      "        guaranteed. If components of y have different scales, it might be\n",
      "        beneficial to set different `atol` values for different components by\n",
      "        passing array_like with shape (n,) for `atol`. Default values are\n",
      "        1e-3 for `rtol` and 1e-6 for `atol`.\n",
      "    jac : array_like, sparse_matrix, callable or None, optional\n",
      "        Jacobian matrix of the right-hand side of the system with respect to\n",
      "        y, required by the 'Radau', 'BDF' and 'LSODA' method. The Jacobian matrix\n",
      "        has shape (n, n) and its element (i, j) is equal to ``d f_i / d y_j``.\n",
      "        There are three ways to define the Jacobian:\n",
      "    \n",
      "            * If array_like or sparse_matrix, the Jacobian is assumed to\n",
      "              be constant. Not supported by 'LSODA'.\n",
      "            * If callable, the Jacobian is assumed to depend on both\n",
      "              t and y; it will be called as ``jac(t, y)`` as necessary.\n",
      "              For the 'Radau' and 'BDF' methods, the return value might be a\n",
      "              sparse matrix.\n",
      "            * If None (default), the Jacobian will be approximated by\n",
      "              finite differences.\n",
      "    \n",
      "        It is generally recommended to provide the Jacobian rather than\n",
      "        relying on a finite-difference approximation.\n",
      "    jac_sparsity : array_like, sparse matrix or None, optional\n",
      "        Defines a sparsity structure of the Jacobian matrix for a\n",
      "        finite-difference approximation. Its shape must be (n, n). This argument\n",
      "        is ignored if `jac` is not `None`. If the Jacobian has only few non-zero\n",
      "        elements in *each* row, providing the sparsity structure will greatly\n",
      "        speed up the computations [10]_. A zero entry means that a corresponding\n",
      "        element in the Jacobian is always zero. If None (default), the Jacobian\n",
      "        is assumed to be dense.\n",
      "        Not supported by 'LSODA', see `lband` and `uband` instead.\n",
      "    lband, uband : int or None, optional\n",
      "        Parameters defining the bandwidth of the Jacobian for the 'LSODA' method,\n",
      "        i.e., ``jac[i, j] != 0 only for i - lband <= j <= i + uband``. Default is\n",
      "        None. Setting these requires your jac routine to return the Jacobian in the\n",
      "        packed format: the returned array must have ``n`` columns and\n",
      "        ``uband + lband + 1`` rows in which Jacobian diagonals are written.\n",
      "        Specifically ``jac_packed[uband + i - j , j] = jac[i, j]``. The same format\n",
      "        is used in `scipy.linalg.solve_banded` (check for an illustration).\n",
      "        These parameters can be also used with ``jac=None`` to reduce the\n",
      "        number of Jacobian elements estimated by finite differences.\n",
      "    min_step : float, optional\n",
      "        The minimum allowed step size for 'LSODA' method. \n",
      "        By default `min_step` is zero.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Bunch object with the following fields defined:\n",
      "    t : ndarray, shape (n_points,)\n",
      "        Time points.\n",
      "    y : ndarray, shape (n, n_points)\n",
      "        Values of the solution at `t`.\n",
      "    sol : `OdeSolution` or None\n",
      "        Found solution as `OdeSolution` instance; None if `dense_output` was\n",
      "        set to False.\n",
      "    t_events : list of ndarray or None\n",
      "        Contains for each event type a list of arrays at which an event of\n",
      "        that type event was detected. None if `events` was None.\n",
      "    nfev : int\n",
      "        Number of evaluations of the right-hand side.\n",
      "    njev : int\n",
      "        Number of evaluations of the Jacobian.\n",
      "    nlu : int\n",
      "        Number of LU decompositions.\n",
      "    status : int\n",
      "        Reason for algorithm termination:\n",
      "    \n",
      "            * -1: Integration step failed.\n",
      "            *  0: The solver successfully reached the end of `tspan`.\n",
      "            *  1: A termination event occurred.\n",
      "    \n",
      "    message : string\n",
      "        Human-readable description of the termination reason.\n",
      "    success : bool\n",
      "        True if the solver reached the interval end or a termination event\n",
      "        occurred (``status >= 0``).\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] J. R. Dormand, P. J. Prince, \"A family of embedded Runge-Kutta\n",
      "           formulae\", Journal of Computational and Applied Mathematics, Vol. 6,\n",
      "           No. 1, pp. 19-26, 1980.\n",
      "    .. [2] L. W. Shampine, \"Some Practical Runge-Kutta Formulas\", Mathematics\n",
      "           of Computation,, Vol. 46, No. 173, pp. 135-150, 1986.\n",
      "    .. [3] P. Bogacki, L.F. Shampine, \"A 3(2) Pair of Runge-Kutta Formulas\",\n",
      "           Appl. Math. Lett. Vol. 2, No. 4. pp. 321-325, 1989.\n",
      "    .. [4] E. Hairer, G. Wanner, \"Solving Ordinary Differential Equations II:\n",
      "           Stiff and Differential-Algebraic Problems\", Sec. IV.8.\n",
      "    .. [5] `Backward Differentiation Formula\n",
      "            <https://en.wikipedia.org/wiki/Backward_differentiation_formula>`_\n",
      "            on Wikipedia.\n",
      "    .. [6] L. F. Shampine, M. W. Reichelt, \"THE MATLAB ODE SUITE\", SIAM J. SCI.\n",
      "           COMPUTE., Vol. 18, No. 1, pp. 1-22, January 1997.\n",
      "    .. [7] A. C. Hindmarsh, \"ODEPACK, A Systematized Collection of ODE\n",
      "           Solvers,\" IMACS Transactions on Scientific Computation, Vol 1.,\n",
      "           pp. 55-64, 1983.\n",
      "    .. [8] L. Petzold, \"Automatic selection of methods for solving stiff and\n",
      "           nonstiff systems of ordinary differential equations\", SIAM Journal\n",
      "           on Scientific and Statistical Computing, Vol. 4, No. 1, pp. 136-148,\n",
      "           1983.\n",
      "    .. [9] `Stiff equation <https://en.wikipedia.org/wiki/Stiff_equation>`_ on\n",
      "           Wikipedia.\n",
      "    .. [10] A. Curtis, M. J. D. Powell, and J. Reid, \"On the estimation of\n",
      "            sparse Jacobian matrices\", Journal of the Institute of Mathematics\n",
      "            and its Applications, 13, pp. 117-120, 1974.\n",
      "    .. [11] `Cauchy-Riemann equations\n",
      "             <https://en.wikipedia.org/wiki/Cauchy-Riemann_equations>`_ on\n",
      "             Wikipedia.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Basic exponential decay showing automatically chosen time points.\n",
      "    \n",
      "    >>> from scipy.integrate import solve_ivp\n",
      "    >>> def exponential_decay(t, y): return -0.5 * y\n",
      "    >>> sol = solve_ivp(exponential_decay, [0, 10], [2, 4, 8])\n",
      "    >>> print(sol.t)\n",
      "    [  0.           0.11487653   1.26364188   3.06061781   4.85759374\n",
      "       6.65456967   8.4515456   10.        ]\n",
      "    >>> print(sol.y)\n",
      "    [[2.         1.88836035 1.06327177 0.43319312 0.17648948 0.0719045\n",
      "      0.02929499 0.01350938]\n",
      "     [4.         3.7767207  2.12654355 0.86638624 0.35297895 0.143809\n",
      "      0.05858998 0.02701876]\n",
      "     [8.         7.5534414  4.25308709 1.73277247 0.7059579  0.287618\n",
      "      0.11717996 0.05403753]]\n",
      "    \n",
      "    Specifying points where the solution is desired.\n",
      "    \n",
      "    >>> sol = solve_ivp(exponential_decay, [0, 10], [2, 4, 8],\n",
      "    ...                 t_eval=[0, 1, 2, 4, 10])\n",
      "    >>> print(sol.t)\n",
      "    [ 0  1  2  4 10]\n",
      "    >>> print(sol.y)\n",
      "    [[2.         1.21305369 0.73534021 0.27066736 0.01350938]\n",
      "     [4.         2.42610739 1.47068043 0.54133472 0.02701876]\n",
      "     [8.         4.85221478 2.94136085 1.08266944 0.05403753]]\n",
      "    \n",
      "    Cannon fired upward with terminal event upon impact. The ``terminal`` and\n",
      "    ``direction`` fields of an event are applied by monkey patching a function.\n",
      "    Here ``y[0]`` is position and ``y[1]`` is velocity. The projectile starts at\n",
      "    position 0 with velocity +10. Note that the integration never reaches t=100\n",
      "    because the event is terminal.\n",
      "    \n",
      "    >>> def upward_cannon(t, y): return [y[1], -0.5]\n",
      "    >>> def hit_ground(t, y): return y[0]\n",
      "    >>> hit_ground.terminal = True\n",
      "    >>> hit_ground.direction = -1\n",
      "    >>> sol = solve_ivp(upward_cannon, [0, 100], [0, 10], events=hit_ground)\n",
      "    >>> print(sol.t_events)\n",
      "    [array([40.])]\n",
      "    >>> print(sol.t)\n",
      "    [0.00000000e+00 9.99900010e-05 1.09989001e-03 1.10988901e-02\n",
      "     1.11088891e-01 1.11098890e+00 1.11099890e+01 4.00000000e+01]\n",
      "    \n",
      "    Use `dense_output` and `events` to find position, which is 100, at the apex of\n",
      "    the cannonball's trajectory. Apex is not defined as terminal, so both apex\n",
      "    and hit_ground are found. There is no information at t=20, so the sol\n",
      "    attribute is used to evaluate the solution. The sol attribute is\n",
      "    returned by setting ``dense_output=True``.\n",
      "    \n",
      "    >>> def apex(t,y): return y[1]\n",
      "    >>> sol = solve_ivp(upward_cannon, [0, 100], [0, 10], \n",
      "    ...                 events=(hit_ground, apex), dense_output=True)\n",
      "    >>> print(sol.t_events)\n",
      "    [array([40.]), array([20.])]\n",
      "    >>> print(sol.t)\n",
      "    [0.00000000e+00 9.99900010e-05 1.09989001e-03 1.10988901e-02\n",
      "     1.11088891e-01 1.11098890e+00 1.11099890e+01 4.00000000e+01]\n",
      "    >>> print(sol.sol(sol.t_events[1][0]))\n",
      "    [100.   0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(solve_ivp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To numerically compute the solution to our ODE, we need to set numeric values to the initial conditions and the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "beta = 0.002 #np.array ([0.0018, 0.0021, 0.0019, 0.0027, 0.0029, 0.0020, 0.0016, 0.0015, 0.0023, 0.0030])\n",
    "alpha = 0.476\n",
    "par = [alpha,beta]\n",
    "    \n",
    "# Define initial conditions\n",
    "N0 = 763\n",
    "I0 = 25\n",
    "R0 = 0\n",
    "S0 = N0 - I0 - R0\n",
    "init_cond = np.array([S0, I0, R0])\n",
    "tspan = (3,50)    \n",
    "t_eval = np.linspace(3., 50., 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to numerically solve our system of ODEs using the initial data and parameter values defined in the previous cell. The output of SolveModel is called a 'bunch object'.  The object's contents, which are the output times 't' and an array 'y' of the numerical solution at each time (each column of this array corresponds to a different state variable, in our case, $S$ and $I$). These outputs are \"dot-accessible\"; that is, they can be accessed using soln.t and soln.y as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prosper/miniconda3/envs/python3/lib/python3.7/site-packages/scipy/integrate/_ivp/common.py:41: UserWarning: The following arguments have no effect for a chosen solver: `args`.\n",
      "  .format(\", \".join(\"`{}`\".format(x) for x in extraneous)))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dydt() missing 1 required positional argument: 'par'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a19533505752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtspan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_cond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a08e72feaba1>\u001b[0m in \u001b[0;36mSolveModel\u001b[0;34m(par, tspan, init_cond, t_eval)\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0minit_cond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0mt_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                          args = (par,))\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mode_soln\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python3/lib/python3.7/site-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, **options)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt_eval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python3/lib/python3.7/site-packages/scipy/integrate/_ivp/rk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, t0, y0, t_bound, max_step, rtol, atol, vectorized, first_step, **extraneous)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_max_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             self.h_abs = select_initial_step(\n",
      "\u001b[0;32m~/miniconda3/envs/python3/lib/python3.7/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python3/lib/python3.7/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dydt() missing 1 required positional argument: 'par'"
     ]
    }
   ],
   "source": [
    "soln = SolveModel(par,tspan,init_cond,t_eval)\n",
    "t = soln.t\n",
    "S = soln.y[0]\n",
    "I = soln.y[1]\n",
    "R = soln.y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the solutions to the SIR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEOCAYAAABM5Pr8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi3klEQVR4nO3deZhddZ3n8fe39uxJpSp7QgKEQIIQQhqigAKKAqLBhRanG2nHFscHHR2Zpx91eqFnHnqYcWt7unUGBMFWoUPLptBsaRAVAZOQhCyELGSpbFVkTyqpVKq+88fv3NQlqarcW3c599z7eT3Pfc6555577jcnz5NPfr/fOb9j7o6IiEguquIuQEREkk9hIiIiOVOYiIhIzhQmIiKSM4WJiIjkrCbuAgqpqanJp06dGncZIiKJsnjx4rfdvTmb75R1mEydOpVFixbFXYaISKKY2aZsv6NuLhERyZnCREREcqYwERGRnClMREQkZwoTERHJmcJERERyVtaXBouIVIKOjg52797NgQMH6Orq6nO/uro6mpqaGDFiRN5rUJjkw9aXYPF3YMIlcNYnYfiUuCsSkQrR0dHB5s2bGTVqFFOnTqW2thYzO2k/d+fw4cO0tLRQX19PQ0NDXutQN1c+/PabsPZh+PVtcPdp8PN5sO3luKsSkQqwe/duRo0aRVNTE3V1db0GCYCZMXjwYJqammhra8t7HbGFiZlNNrPnzWy1ma00s69E2283s61mtjR6XZv2nW+Y2TozW2NmH4qr9ndob4Otv4GqWpj+CagZBNtfgSf/BPTgMREpsAMHDjB8+PCM9x82bBhHjhzJex1xdnMdA25z9yVmNgxYbGbPRp99z92/nb6zmc0EbgRmAROA58zsLHfvu4OwGNb/ErwbTvsgfPRfofMQ/OgM2LcBWl+DsXNiLU9EyltXVxe1tbUZ719TU8OxY8fyXkdsLRN33+7uS6L1A8BqYGI/X5kPPOjuHe7+FrAOuKjwlZ7CukfD8szrw7J2SGihAKxZEEdFIlJh+uraynXfbJTEmImZTQUuAF6JNn3JzJab2b1mNiraNhHYkva1FnoJHzO7xcwWmdmiQvQLvsPRg7DpGcDgzPk922f8cVi++ZC6ukSkIsQeJmY2FPgF8FV33w/8EDgDmA1sB76T2rWXr5/0L7W73+Xuc919bnNzVjMoZ2/j09DVAePnwZBxPdsnXgqDx0ZdXUsKW4OISAmINUzMrJYQJD9z94cB3H2nu3e5ezdwNz1dWS3A5LSvTwK2FbPek6x7JCxTXVwpVdXhEmGANQ8VtSQRkTjEeTWXAfcAq939u2nbx6ft9jFgRbT+OHCjmdWb2TRgOvBqseo9SVcnbPhVWJ/+sZM/P97VtUBdXSJS9uK8musS4CbgdTNbGm37JvBpM5tN6MLaCHwBwN1XmtkCYBXhSrBbY72Sa8sL0LEPRs+EUdNP/nzCJaHra99boatr7IXFrlBEKoS7Zzyw7gX6z21sYeLuv6X3cZAn+/nOHcAdBSsqG8ev4uqlVQKhq2v6J2HpP4aruhQmIlIAdXV1HD58mMGDB2e0/+HDh7O6lDhTsQ/AJ5I7rH8srJ84XpJuxg1huUZdXSJSGE1NTbS0tLB79246Ozv7bHm4O+3t7WzdupUxY8bkvQ7NzTUQ7Tvh4FaoH9F/iyPV1bV/I+xaBU2zilaiiFSGESNGUF9fT1tbG7t27er3hsTa2lrGjh2b1R3zmVKYDMTuNWHZeDb0109ZVQ0TLwv3m2x/WWEiIgXR0NDA5MmTT71jAambayD2RGEyasap9x0/Lyy3a+JHESlfCpOBON4yySRMLg7L7a/0v5+ISIIpTAYim5bJmDlQVQNvr4CjBwpbl4hITBQmA5FqmYw669T71g6C5vMBhx2LClqWiEhcFCbZ6joabkTEYOSZmX3n+LiJurpEpDwpTLK1dz14Fww/LbQ6MnF83ESD8CJSnhQm2cpm8D1lXBQmO17RzYsiUpYUJtnKZvA9ZdR0aBgFh3bAgc2FqUtEJEYKk2zteTMss2mZmPW0TjRuIiJlSGGSrd0DaJmABuFFpKwpTLK1ZwBjJqBBeBEpawqTbBzeDYffhtohMPSkx8/3b1z0wMjWJeHyYhGRMqIwycaetJsVM3wQzXGDGsP3jh2BtuX5r01EJEYKk2wMdLwkRfN0iUiZUphkY6DjJSnpXV0iImVEYZKNXFsmzeeHZevSvJQjIlIqFCbZyLVl0nxeWO5aCd19Pw1NRCRpFCaZ6u6CvevC+qjpAztG/QgYMQ26OnpaOSIiZUBhkqn9m8IlvUMnQN2wgR8n1dXVtiw/dYmIlACFSaYGMidXbxQmIlKGFCaZ2rs+LAfaxZWiQXgRKUMKk0wdaAnLYVNyO45aJiJShhQmmTqwJSyHTcrtOCOmhjGX9p1waGfOZYmIlAKFSaYORi2ToTmGiVWpdSIiZUdhkqnjLZPJuR9LYSIiZUZhkgnvhoNbw3qu3VygMBGRsqMwyUR7W7jHpKERagfnfjxd0SUiZSa2MDGzyWb2vJmtNrOVZvaVaHujmT1rZmuj5ai073zDzNaZ2Roz+1DRik2Nl+SjVQLQdG4YO9n9RpiSXkQk4eJsmRwDbnP3c4B5wK1mNhP4OrDQ3acDC6P3RJ/dCMwCrgZ+YGbVRan0+GXBeRgvgdC6GTkdvAt2rcrPMUVEYhRbmLj7dndfEq0fAFYDE4H5wP3RbvcD10fr84EH3b3D3d8C1gEXFaXY1OB7rldypRszOyw1biIiZaAkxkzMbCpwAfAKMNbdt0MIHGBMtNtEYEva11qibSce6xYzW2Rmi9ra2vJTYL5bJqBBeBEpK7GHiZkNBX4BfNXd9/e3ay/b/KQN7ne5+1x3n9vc3JyfIvN1w2I6DcKLSBmJNUzMrJYQJD9z94ejzTvNbHz0+XigNdreAqQ3DSYB24pSaL5uWEyX3jLxkzJRRCRR4ryay4B7gNXu/t20jx4Hbo7WbwYeS9t+o5nVm9k0YDrwalGKzecNiylDJ4RLjTv29tzDIiKSUHG2TC4BbgKuNLOl0eta4E7gKjNbC1wVvcfdVwILgFXAU8Ct7t5V8CrzfcNiilnPkxfffj1/xxURiUFNXD/s7r+l93EQgPf38Z07gDsKVlRvDr+d3xsW0zW9C7a8AG3LYdo1+T22iEgRxT4AX/IKMfie0qSWiYiUB4XJqRTisuCU5neFZdvy/B9bRKSIFCanUogbFlNGzwIsTKvSdTT/xxcRKRKFyakUsmVSNxRGng7dnbB7Tf6PLyJSJAqTUynkmAmkjZuoq0tEkkthciqFuGExXVNq3ESD8CKSXAqTUynEDYvpmtUyEZHkU5j0p1A3LKZTy0REyoDCpD+FvGExZeQZUDModKcd2VOY3xARKTCFSX8KPfgOUFUdnrwIunlRRBJLYdKfQl4WnK5JNy+KSLIpTPpTyBsW02nCRxFJOIVJf9QyERHJiMKkP8UYM4GeMHl7RbiCTEQkYRQm/Sn0DYspg5thyDjoPAj7Nhb2t0RECkBh0p+D0VOBC90ygZ5pVdTVJSIJpDDpi3vPDYtDJxT+99KfCS8ikjAKk7507INjh6F2KNQNK/zvjUmFydLC/5aISJ4pTPpyKOriKkarBKB5dliqZSIiCaQw6UtqvGToxOL8XuMMqK6HfW+FVpGISIIoTPpSzPESgKqa6MmLaBBeRBJHYdKXVMtkSJHCBGDM7LBUV5eIJIzCpC8HizxmAj1XdLUuLd5viojkgcKkL8e7uYo0ZgJqmYhIYilM+lLsq7kg7Xnwr0P3seL9rohIjhQmfYmjm6thJAw/Dbo6YM+bxftdEZEcKUx6491waHtYHzK+uL+dut+kVV1dIpIcCpPetLeFbqaG0VDTUNzfbtad8CKSPAqT3sTRxZWiQXgRSaDYwsTM7jWzVjNbkbbtdjPbamZLo9e1aZ99w8zWmdkaM/tQQYuLY/A9RZcHi0gCxdkyuQ+4upft33P32dHrSQAzmwncCMyKvvMDM6suWGVx3LCYMmJqmFiyfScc2ln83xcRGYDYwsTdXwR2Z7j7fOBBd+9w97eAdcBFBSsudY/JsCLeY5JiVZqOXkQSpxTHTL5kZsujbrBR0baJwJa0fVqibYURZ8sE1NUlIolTamHyQ+AMYDawHfhOtN162dd7O4CZ3WJmi8xsUVtb28CqiHPMBNKmo18az++LiGSppMLE3Xe6e5e7dwN309OV1QJMTtt1ErCtj2Pc5e5z3X1uc3PzwAop9vTzJxo7Jyx3Lo7n90VEslRSYWJm6XcIfgxIXen1OHCjmdWb2TRgOvBqwQop9vTzJ2o6F6rrwl3wHfvjqUFEJAs1cf2wmT0AXA40mVkL8DfA5WY2m9CFtRH4AoC7rzSzBcAq4Bhwq7t3FaSwrk5obw0D4YPHFOQnTqm6LszTtXMRtC6ByZfHU4eISIZiCxN3/3Qvm+/pZ/87gDsKV1Hk0I6wHDw2PLAqLuPmhjDZsUhhIiIlr6S6uUrCoZjHS1LGXBiWGjcRkQRQmJwo7vGSlHFzw3LnonjrEBHJgMLkRHHOy5Vu9Cyoroe96+DI3nhrERE5hawGBcxsHmE6k3nABGAQ8DawBvg18Ki778l3kUUV9w2LKdW14ebFHa+GQfgpV8Zbj4hIPzJqmZjZzWb2OvAS8FVgMLAWeAXYA1wM/AjYamb3RZfvJlMcj+vty9ioq2uHurpEpLSdsmViZsuAMcBPgM8AS939pLvPzWwEcB3wJ8BKM/usu/9LnustvFLp5oIwbrIMjZuISMnLpJvrx8D/dfcj/e3k7vuAnwE/M7PzgXF5qK/44p5KJd1YXdElIslwyjBx97/P9qDuvozwf+rkKZUxE4DRM8OTHvdtgMO7YVBj3BWJiPQqq6u5zGyBmU0+9Z4J1dkOHXvDHeiDRsddTbhpsvmCsK7WiYiUsGwvDf4kML63D8ys0czek3tJMTreKhkP1ttExTFQV5eIJEAmA/Azov1Wn2LX6cBvgMI9AbHQDkSPTBlWQo0v3bwoIgmQScvkRuB14CBhAsZvmtl/NrNLzWxo2n4jgH4H6UteKYbJWIWJiJS+TK7m+i7wIjAH+BZwLuHGxTqg28zWE2bzPR9YXqA6i6MUw6TxbKgZDPs3hdmM45rJWESkH6dsmbj7AXd/3t2/A7wBfAoYRgiXW4BngOHAa8CfF7DWwivFMKmqhvHRM8K2/T7eWkRE+pDVdCruPjPt7dLoVT5KMUwAJlwCW16AbS/BmfPjrkZE5CSa6DFdyYZJdJHctpfirUNEpA+nDBMze8zMLsj0gGbWYGZfM7P/lFtpMSjVMBk/Lyx3/AG6jsZbi4hILzJpmWwGXjazV6KruOaY2Tu6x8xsgpldb2b3ANuB/wgsKUC9hXP0YLhhsaYBBjXFXc07DWqExnOgqwNaX4u7GhGRk2QyAP9lYCbwKnA78AfgiJntNrPtZnYE2AI8DMwizCp8nru/WqiiCyLVKhk6qXRuWEyX6ura+rt46xAR6UVGA/Duvh74spndBrybMOX8BKAB2EW4yutFd99UqEIL7sDmsCy1Lq6UCe+BFfdE4yZfi7saEZF3yOQO+AuAFe7e6e5HCQ/B+nXBKyu2/SU6XpJyfBD+d+Bemq0nEalYmbRMFgOdZraKcCnwa9FrmbvvL2BtxVWqg+8pjWdBQyMc2hFuYBwxNe6KRESOyyRMvkC4u3028AngZsK0KpjZW4RgWZpauvu2QhRacKUeJlYFE94NG54IXV0KExEpIZk8z+Tu9PdmNp0QLBdEy0sIIQMhZJI50WOphwmErq5UmJzzH+KuRkTkuKzugAdw97WE578/lNpmZmMI06ucn7/SiiwRYXJJWOrmRREpMVmHSW/cvRV4Knolj3tPmAyfEm8t/Rn3R2DV0LYs3BdTN/TU3xERKQJNpwJwZA8ca4e6YVA/Iu5q+lY7GMZcAN4NO5J1G4+IlDeFCSSjiysldYlwy4vx1iEikkZhAskKk8lXhOXmf4+3DhGRNAoTSFiYvC9cJrz9Zeg8FHc1IiJAjGFiZveaWauZrUjb1mhmz5rZ2mg5Ku2zb5jZOjNbY2YfymsxSQqThlEwZg50d2qeLhEpGXG2TO4jPP433deBhe4+HVgYvcfMZhKeRT8r+s4PzCx/97MkKUwAplwZlurqEpESEVuYuPuLwO4TNs8H7o/W7weuT9v+oLt3uPtbwDrgorwVk9gwWRhvHSIikVIbMxnr7tsBouWYaPtEwjT3KS3RtpOY2S1mtsjMFrW1tWX2q0kLk4mXQlUttC4JlzWLiMSs1MKkL71Nkeu97ejud7n7XHef29zcfOojezccbAnrSQmT2iHh6YverUuERaQklFqY7DSz8QDRsjXa3gKk/0s/CcjPhJLtbeFRuA2N4abApFBXl4iUkFILk8cJsxITLR9L236jmdWb2TRgOuHJj7lLWhdXigbhRaSE5GVuroEwsweAy4EmM2sB/ga4E1hgZp8jPHv+BgB3X2lmC4BVwDHgVnfvykshSQ2TcRdDzSDYtRIO7YQhY+OuSEQqWGxh4u6f7uOj9/ex/x3AHXkvJKlhUlMPEy+DTc/Alufh7BvjrkhEKlipdXMV3/7osfVJCxPQuImIlAyFyd51YTnyzHjrGIhUmGx8JkyjLyISE4XJnrVhOWp6vHUMxNgLYVAzHNgcxk5ERGJS2WHS3QX71of1JLZMrApO/3BYX/+reGsRkYpW2WFysCXcYzJkXHKfWnj6dWG5QWEiIvGp7DBJdXGNTGAXV8ppV4WpVbb/HtrfjrsaEalQChNI5nhJSv1wmPS+MLXKxqfirkZEKlRlh0mSr+RKd4a6ukQkXpUdJuXQMoGecZONT0FXZ7y1iEhFquww2VsGYyYAI8+AxrOhYx9s09MXRaT4KjdMurtg34awPirh3VzQ0zrRJcIiEoPKDZMDW6LLgseH54MkXSpM3noi3jpEpCJVbpiUy3hJyoT3QP1I2P0G7H4z7mpEpMJUbpiUy3hJSnUtnPGRsL7mX+KtRUQqTgWHSZlcFpzu7GhW/zce0MSPIlJUlRsm5dbNBTDlA9AwGnavhrblcVcjIhVEYVJOYVJdCzNuCOtvPBBvLSJSUSozTLqP9VwWPPKMeGvJt1RX15oH1dUlIkVTmWFyYAt0d8LQCeVxWXC6iZfC0EnhCZLbfh93NSJSISozTMphtuC+WBXM+FRYV1eXiBRJZYdJOY2XpDsn6up6c0Ho0hMRKbDKDJNyvCw43Zg5ISjbW2Hz83FXIyIVoELDpMxbJmYwI2qdrPpJvLWISEWozDAp5zGTlHP/DLDQ1aUnMIpIgVVemHS2h24uqy7fbi6AEdNg2tVhMsuVP467GhEpc5UXJm3LwiNuR8+E2kFxV1NY538xLJf/v/BnFhEpkMoLk52Lw3LshfHWUQzTroVhU2Dvetj0bNzViEgZU5iUs6pqOO+WsL70h/HWIiJlTWFS7t71OaiqgQ2/hP1b4q5GRMpUZYVJ52HYtSrcJd58ftzVFMeQcXDmx8OYyet3x12NiJSpkgwTM9toZq+b2VIzWxRtazSzZ81sbbQclfWB25aBd0WD74PzXnfJmh0NxL9+Nxw7Em8tIlKWSjJMIle4+2x3nxu9/zqw0N2nAwuj99mptC6ulEnvCy2xQztgxb1xVyMiZaiUw+RE84H7o/X7geuzPkIqTMbMyVNJCWEG8/4yrL96Z7j3REQkj0o1TBx4xswWm1l0ORJj3X07QLQc09sXzewWM1tkZova2tre+WHrkuhIFdYyAZj+cWg8J0y/v+qf465GRMpMqYbJJe4+B7gGuNXM3pvpF939Lnef6+5zm5ubez44dgR2rQyD72Nm573gkmdVMO+/hfVX/k6zCYtIXpVkmLj7tmjZCjwCXATsNLPxANGyNauDti0P/4A2nl1+D8TK1IxPhSlk9m3Qs05EJK9KLkzMbIiZDUutAx8EVgCPAzdHu90MPJbVgSt18D1dVQ1c/M2w/vId0N0Vbz0iUjZKLkyAscBvzWwZ8CrwhLs/BdwJXGVma4GroveZU5gE5/wpDJ8Ke9bAGz+PuxoRKRM1cRdwInffAJx0R6G77wLeP+ADH7+Sq8LDpLoW3nM7PPVn8Juvw5kfg7qhcVclIglXii2T/Dt2BHatAKwyB99PNPMmGHcRHNwWBuNFRHJUGWHy9uvR4PsM/S8cwpVdV/5DWF/8HdizLt56RCTxKiNMNi0My/HvjreOUjL+Ypj5mXAD469vi7saEUm4ygiTt54Iy9M/HG8dpeayO6F2KKx/HDY+E3c1IpJg5R8mh3fBtpegqhZOuyruakrL0PE906w890U4ejDeekQksco/TDY+HaZfn/ReqB8edzWl58L/EiaB3LcBXvha3NWISEKVf5hs+FVYqourd9V1cO1Pobo+TFG//pdxVyQiCVTmYeKw8amwevp18ZZSyprOhcv+Z1h/5s+hPbuZakREyjtMjh6CI3tg1PTwkr7N+QpMviIEyTOfB/e4KxKRBCnzMNkXlmqVnJpVwdX3Qf2IcHWXbmYUkSyUd5h07A3LaRovycjwKXDNPwMGv/tLePMXcVckIglR3mFy7AjUDYNJl8VdSXKc8RF47/8O6/92E+xcEm89IpII5R0mAKd9MFyxJJmbexvM+iwcOwyPfhQObI27IhEpceUfJhovyZ4ZfOCHMPFSOLgVHroyTAopItKH8g6ThkaYdk3cVSRTTT3MfzTc0LjnTVhwuVooItKn8g6TEdNgyNi4q0iuQaPhhoXQPBv2rIWHrlCgiEivyjtMJHeDRsMNz8GYC0KgPHgJtC2PuyoRKTEKEzm1QaPhk8+Faev3b4IH3gNrH4m7KhEpIQoTycygRvjjF8Iz5DsPweMfh9//jzCJpohUPIWJZK6mAa75CVz2vwCDl/4aFlwJ+zbGXZmIxExhItkxg4v+Aj7+BAweAy2/hvvfBct/pPm8RCqYwkQGZto1cPNKOOuT0HkQnv08LLgCdr4Wd2UiEgOFiQzc4Ca4bgFc+3NoGB1aKT+9EJ7+HBzcHnd1IlJEChPJjRmc82n43Nrw1MaqalhxL9xzBiz8ssZTRCqEwkTyo2EUXP7d0PV15vVhXq+l/wj3nAlP3gRbX9KYikgZU5hIfjWeBfMfgc8sD5cRA6z+abjZ8b5Z8IdvqwtMpAyZl/H/FufOneuLFi2Ku4zKtm8jLPshrLwf2ndGGw3Gz4PpH4cz58PIM0N3mYiUBDNb7O5zs/qOwkSKoqsT3noSVvwYNj4FXR09nw0/Daa8P7wmXgrDJitcRGKkMDmBwqREHT0YAmXtw7DxaTiy+52fDxkPE94NY+dC83nQdB4Mm6SAESkShckJFCYJ4N3QuhQ2L4Qtz8P2l+HInpP3qx8Jo87qeY2YBsOnhlbN0AnhKjIRyYuKCBMzuxr4PlAN/Mjd7+xrX4VJArmH56dsfzmETNuy8Dqx9ZLOqmDIuNCiGTIeBo+Fwc0wqBkGNYXn2jQ0QsNIqBsB9SOgdohaOiJ9GEiY1BSqmEIws2rgn4CrgBbgD2b2uLuvircyyRszaJwRXrNuDtvcw+D9nrUhaPa8GQb2D2wKy/ad4UmQ2TwN0qqgdmgIlbqhUDMEagdDzWCoGRTmIatpgOoGqK4Pr5p6qKoLj4GuroOq2uhVE72idatOW1aHpVWlva8CqtLWLfo8fd1OXsfStqeCMG1b6vy9Y52e9+nr6fuln/sT9+v13PUXwhkGdOKCPGn1Fl+iwgS4CFjn7hsAzOxBYD6gMClnZlHLYxxMuuzkz7uOwqGdcCgKlMNt0N4G7a2hRXP8tQeO7oeOfXCsPawf3Q+Hiv9HEik3SQuTicCWtPctwMXpO5jZLcAtAFOmTCleZRKf6joYPjm8MtV9LEylf/RgmFussz0ETGd72N7VAV1H4NiRaD391QndnSHE/FjPe+8Kx029vCva1hXGhvzEZWrdAQ/7Ea17d8/29HU87eZPT9tOL+v0vD9p2wnd2+/o7u6n67vfbvEMu8wT1rWe8Z+rrLyd9TeSFia9tTXf8Tft7ncBd0EYMylGUZJAVTVh7KR+RNyViJSeW7Pv1kvaHfAtQPp/PycBWXSUi4hIISQtTP4ATDezaWZWB9wIPB5zTSIiFS9R3VzufszMvgQ8Tbg0+F53XxlzWSIiFS9RYQLg7k8CT8Zdh4iI9EhaN5eIiJQghYmIiORMYSIiIjlTmIiISM4SN9FjNsysDdgUdx150MRAbkmtDDo3/dP56ZvOTd9muPuwbL6QuKu5suHuzXHXkA9mtijbGTwrhc5N/3R++qZz0zczy3q6dXVziYhIzhQmIiKSM4VJMtwVdwElTOemfzo/fdO56VvW56asB+BFRKQ41DIREZGcKUxERCRnCpMSY2b3mlmrma1I29ZoZs+a2dpoOSrOGuNiZpPN7HkzW21mK83sK9H2ij8/ZtZgZq+a2bLo3PxttL3iz02KmVWb2Wtm9qvovc5NxMw2mtnrZrY0dVlwtudHYVJ67gOuPmHb14GF7j4dWBi9r0THgNvc/RxgHnCrmc1E5wegA7jS3c8HZgNXm9k8dG7SfQVYnfZe5+adrnD32Wn33mR1fhQmJcbdXwR2n7B5PnB/tH4/cH0xayoV7r7d3ZdE6wcI/zBMROcHDw5Gb2ujl6NzA4CZTQI+DPwobbPOTf+yOj8Kk2QY6+7bIfyDCoyJuZ7YmdlU4ALgFXR+gOPdOEuBVuBZd9e56fH3wF8A3WnbdG56OPCMmS02s1uibVmdn7KeTkXKk5kNBX4BfNXd95tZ3CWVBHfvAmab2UjgETM7N+aSSoKZXQe0uvtiM7s85nJK1SXuvs3MxgDPmtkb2R5ALZNk2Glm4wGiZWvM9cTGzGoJQfIzd3842qzzk8bd9wIvEMbedG7gEuCjZrYReBC40sx+is7Nce6+LVq2Ao8AF5Hl+VGYJMPjwM3R+s3AYzHWEhsLTZB7gNXu/t20jyr+/JhZc9QiwcwGAR8A3kDnBnf/hrtPcvepwI3Av7v7n6JzA4CZDTGzYal14IPACrI8P7oDvsSY2QPA5YTpsXcCfwM8CiwApgCbgRvc/cRB+rJnZpcCvwFep6fv+5uEcZOKPj9mdh5hkLSa8J/EBe7+381sNBV+btJF3Vz/1d2v07kJzOx0QmsEwtDHz939jmzPj8JERERypm4uERHJmcJERERypjAREZGcKUxERCRnChMREcmZwkRERHKmMBERkZwpTEQAM/MMXhvN7HYzK+mbs8xseFTnOXHXIpVDNy2KANGzP9I9AiwDbk/b1gG0AZPc/eUilZY1M7uS8PyJ8919edz1SGXQrMEiwInhYGYdwNt9hEZLcaoasAsIwbcq7kKkcqibSyQLvXVzpbaZ2dlm9rSZHTKzzWb22ejzm8zsDTM7GD12+IwTvn++mT1uZnvM7LCZ/c7MLhtgfauBbwP1QGdU178O8I8rkjGFiUj+PAQ8QXgi3WLgXjP7O+CLhEeefhaYAfw89QUzmwO8BDQCnwc+AewCnjOzCwdQw2eADcAvgXdHr9sG9scRyZy6uUTy51vu/hMAM1sEfAT4AjDN3fdH28cD3zez09x9E/AtwoysV7r70WifpwlTgP8V2T9KdhkwCfg/pTyuI+VHLROR/Pm31Iq77yE8TOjlVJBEUk+wmxw9d+R9hBZNt5nVmFkNYMBzwHsHUMMsoA5YMoDvigyYWiYi+bPnhPdH+9gG0EDo2qomtED+qrcDmlmVu3f39lkf5hCe5700i++I5ExhIhKfvYSHfP0T8JPedsgySCBcybX+hNaQSMEpTERi4u6HzOw3wPnAkgEER29mokuCJQYKE5F4fQ14EXjazO4BthMe2TwHqHb3rwOY2VTgLeBv3f32fo63F5hjZh8C9gFr3X1XwaoXiWgAXiRG7r4E+CPC5cD/ADwDfB94FyFkUoZEyx2nOORfAzuBR4HfA5pSRYpC06mIJICZ3QLcAZzm7u1x1yNyIrVMRJLhfcD3FCRSqtQyERGRnKllIiIiOVOYiIhIzhQmIiKSM4WJiIjkTGEiIiI5U5iIiEjOFCYiIpKz/w8rXckXmVBd/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t, I, c='darkorange',  linewidth=2,)\n",
    "plt.legend(fontsize=16)\n",
    "    \n",
    "xmin = t[0]\n",
    "xmax = t[-1]\n",
    "plt.xlim(xmin, xmax)\n",
    "    \n",
    "xmin = t[0]\n",
    "xmax = t[-1]\n",
    "plt.xlim(xmin, xmax)\n",
    "    \n",
    "plt.xlabel(\"Time, $t$\", fontsize=16)\n",
    "plt.ylabel(\"$I(t)$\",fontsize=16)\n",
    "\n",
    "# NOTE: if you want to save a figure, you can do so as follows.\n",
    "plt.savefig('SIRplot_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting SIR Model to Boarding School Data\n",
    "We first need to define an objective function to be minimized.  For now, we will define this objective function to be the sum of squared residuals (SSR) $\\sum_{i=1}^n (I(t_i,\\theta)) - d(t_i))^2$, where $I(t)$ is the number of infected individuals from the ODE solution at time $t$, and $d(t)$ is the number of infected individuals at time $t$ from the data. Note that the solution to the ODE depends on the parameters $\\theta=(\\beta,\\alpha)$. Our goal is to find the parameter vector $\\theta$ that minimized the SSR. Later on, we will consider other types of objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to be able to pass in the parameters, the time data, and the infected count data\n",
    "def objective_fun(par,tdat,ydat,init_cond): \n",
    "    \n",
    "    par = np.abs(par)\n",
    "    \n",
    "    tspan = (tdat[0],tdat[-1]);\n",
    "    t_eval = tdat;\n",
    "    \n",
    "    # Solve the model with the parameters in par\n",
    "    soln = SolveModel(par,tspan,init_cond,t_eval)\n",
    "    \n",
    "    \n",
    "    # Extract the solution for the number infected over time\n",
    "    I = soln.y[1]\n",
    "            \n",
    "    # Compute the SSR\n",
    "    SSR = np.sum((I-ydat)**2)\n",
    "\n",
    "    # Return the SSR for this parameter set and data.\n",
    "    return SSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will allow us to minimize the objective function defined in 'objective_fun'. First, we need to import the function scipy.optimize as optimize from the scipy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy as sp\n",
    "# from scipy.integrate import solve_ivp\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define arrays for the time (tdata) and infected count data (ydata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = np.array([1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "ydata = np.array([3, 25, 75, 227, 296, 258, 236, 192, 126, 71, 28, 11, 7])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ydata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b30bc5910090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define initial conditions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m763\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mI0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mR0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mS0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mI0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mR0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ydata' is not defined"
     ]
    }
   ],
   "source": [
    "p0 = [.1,.007]#par \n",
    "\n",
    "# Define initial conditions\n",
    "N0 = 763\n",
    "I0 = ydata[0]\n",
    "R0 = 0\n",
    "S0 = N0 - I0 - R0\n",
    "init_cond = np.array([S0, I0, R0])\n",
    "\n",
    "# meth = 'Nelder-Mead'\n",
    "meth = 'BFGS'\n",
    "\n",
    "    \n",
    "optimizer = optimize.minimize(objective_fun, p0, args=(tdata,ydata,init_cond), method=meth,disp=True)\n",
    "best_par = optimizer.x\n",
    "\n",
    "tspan_new = (tdata[0],tdata[-1])\n",
    "fit_soln = SolveModel(best_par,tspan_new,init_cond,tdata)\n",
    "\n",
    "plt.plot(fit_soln.t,fit_soln.y[1])\n",
    "plt.plot(tdata,ydata,'.')\n",
    "\n",
    "best_par,p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 4: Select a data fitting example from Ch. 6.  In the cells below, or in a new Jupyter notebook, modify the code to fit the model to the given data.  What parameter estimates do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function minimize in module scipy.optimize._minimize:\n",
      "\n",
      "minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None, callback=None, options=None)\n",
      "    Minimization of scalar function of one or more variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fun : callable\n",
      "        The objective function to be minimized.\n",
      "    \n",
      "            ``fun(x, *args) -> float``\n",
      "    \n",
      "        where x is an 1-D array with shape (n,) and `args`\n",
      "        is a tuple of the fixed parameters needed to completely\n",
      "        specify the function.\n",
      "    x0 : ndarray, shape (n,)\n",
      "        Initial guess. Array of real elements of size (n,),\n",
      "        where 'n' is the number of independent variables.\n",
      "    args : tuple, optional\n",
      "        Extra arguments passed to the objective function and its\n",
      "        derivatives (`fun`, `jac` and `hess` functions).\n",
      "    method : str or callable, optional\n",
      "        Type of solver.  Should be one of\n",
      "    \n",
      "            - 'Nelder-Mead' :ref:`(see here) <optimize.minimize-neldermead>`\n",
      "            - 'Powell'      :ref:`(see here) <optimize.minimize-powell>`\n",
      "            - 'CG'          :ref:`(see here) <optimize.minimize-cg>`\n",
      "            - 'BFGS'        :ref:`(see here) <optimize.minimize-bfgs>`\n",
      "            - 'Newton-CG'   :ref:`(see here) <optimize.minimize-newtoncg>`\n",
      "            - 'L-BFGS-B'    :ref:`(see here) <optimize.minimize-lbfgsb>`\n",
      "            - 'TNC'         :ref:`(see here) <optimize.minimize-tnc>`\n",
      "            - 'COBYLA'      :ref:`(see here) <optimize.minimize-cobyla>`\n",
      "            - 'SLSQP'       :ref:`(see here) <optimize.minimize-slsqp>`\n",
      "            - 'trust-constr':ref:`(see here) <optimize.minimize-trustconstr>`\n",
      "            - 'dogleg'      :ref:`(see here) <optimize.minimize-dogleg>`\n",
      "            - 'trust-ncg'   :ref:`(see here) <optimize.minimize-trustncg>`\n",
      "            - 'trust-exact' :ref:`(see here) <optimize.minimize-trustexact>`\n",
      "            - 'trust-krylov' :ref:`(see here) <optimize.minimize-trustkrylov>`\n",
      "            - custom - a callable object (added in version 0.14.0),\n",
      "              see below for description.\n",
      "    \n",
      "        If not given, chosen to be one of ``BFGS``, ``L-BFGS-B``, ``SLSQP``,\n",
      "        depending if the problem has constraints or bounds.\n",
      "    jac : {callable,  '2-point', '3-point', 'cs', bool}, optional\n",
      "        Method for computing the gradient vector. Only for CG, BFGS,\n",
      "        Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,\n",
      "        trust-exact and trust-constr. If it is a callable, it should be a\n",
      "        function that returns the gradient vector:\n",
      "    \n",
      "            ``jac(x, *args) -> array_like, shape (n,)``\n",
      "    \n",
      "        where x is an array with shape (n,) and `args` is a tuple with\n",
      "        the fixed parameters. Alternatively, the keywords\n",
      "        {'2-point', '3-point', 'cs'} select a finite\n",
      "        difference scheme for numerical estimation of the gradient. Options\n",
      "        '3-point' and 'cs' are available only to 'trust-constr'.\n",
      "        If `jac` is a Boolean and is True, `fun` is assumed to return the\n",
      "        gradient along with the objective function. If False, the gradient\n",
      "        will be estimated using '2-point' finite difference estimation.\n",
      "    hess : {callable, '2-point', '3-point', 'cs', HessianUpdateStrategy},  optional\n",
      "        Method for computing the Hessian matrix. Only for Newton-CG, dogleg,\n",
      "        trust-ncg,  trust-krylov, trust-exact and trust-constr. If it is\n",
      "        callable, it should return the  Hessian matrix:\n",
      "    \n",
      "            ``hess(x, *args) -> {LinearOperator, spmatrix, array}, (n, n)``\n",
      "    \n",
      "        where x is a (n,) ndarray and `args` is a tuple with the fixed\n",
      "        parameters. LinearOperator and sparse matrix returns are\n",
      "        allowed only for 'trust-constr' method. Alternatively, the keywords\n",
      "        {'2-point', '3-point', 'cs'} select a finite difference scheme\n",
      "        for numerical estimation. Or, objects implementing\n",
      "        `HessianUpdateStrategy` interface can be used to approximate\n",
      "        the Hessian. Available quasi-Newton methods implementing\n",
      "        this interface are:\n",
      "    \n",
      "            - `BFGS`;\n",
      "            - `SR1`.\n",
      "    \n",
      "        Whenever the gradient is estimated via finite-differences,\n",
      "        the Hessian cannot be estimated with options\n",
      "        {'2-point', '3-point', 'cs'} and needs to be\n",
      "        estimated using one of the quasi-Newton strategies.\n",
      "        Finite-difference options {'2-point', '3-point', 'cs'} and\n",
      "        `HessianUpdateStrategy` are available only for 'trust-constr' method.\n",
      "    hessp : callable, optional\n",
      "        Hessian of objective function times an arbitrary vector p. Only for\n",
      "        Newton-CG, trust-ncg, trust-krylov, trust-constr.\n",
      "        Only one of `hessp` or `hess` needs to be given.  If `hess` is\n",
      "        provided, then `hessp` will be ignored.  `hessp` must compute the\n",
      "        Hessian times an arbitrary vector:\n",
      "    \n",
      "            ``hessp(x, p, *args) ->  ndarray shape (n,)``\n",
      "    \n",
      "        where x is a (n,) ndarray, p is an arbitrary vector with\n",
      "        dimension (n,) and `args` is a tuple with the fixed\n",
      "        parameters.\n",
      "    bounds : sequence or `Bounds`, optional\n",
      "        Bounds on variables for L-BFGS-B, TNC, SLSQP and\n",
      "        trust-constr methods. There are two ways to specify the bounds:\n",
      "    \n",
      "            1. Instance of `Bounds` class.\n",
      "            2. Sequence of ``(min, max)`` pairs for each element in `x`. None\n",
      "               is used to specify no bound.\n",
      "    \n",
      "    constraints : {Constraint, dict} or List of {Constraint, dict}, optional\n",
      "        Constraints definition (only for COBYLA, SLSQP and trust-constr).\n",
      "        Constraints for 'trust-constr' are defined as a single object or a\n",
      "        list of objects specifying constraints to the optimization problem.\n",
      "        Available constraints are:\n",
      "    \n",
      "            - `LinearConstraint`\n",
      "            - `NonlinearConstraint`\n",
      "    \n",
      "        Constraints for COBYLA, SLSQP are defined as a list of dictionaries.\n",
      "        Each dictionary with fields:\n",
      "    \n",
      "            type : str\n",
      "                Constraint type: 'eq' for equality, 'ineq' for inequality.\n",
      "            fun : callable\n",
      "                The function defining the constraint.\n",
      "            jac : callable, optional\n",
      "                The Jacobian of `fun` (only for SLSQP).\n",
      "            args : sequence, optional\n",
      "                Extra arguments to be passed to the function and Jacobian.\n",
      "    \n",
      "        Equality constraint means that the constraint function result is to\n",
      "        be zero whereas inequality means that it is to be non-negative.\n",
      "        Note that COBYLA only supports inequality constraints.\n",
      "    tol : float, optional\n",
      "        Tolerance for termination. For detailed control, use solver-specific\n",
      "        options.\n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options()`.\n",
      "    callback : callable, optional\n",
      "        Called after each iteration. For 'trust-constr' it is a callable with\n",
      "        the signature:\n",
      "    \n",
      "            ``callback(xk, OptimizeResult state) -> bool``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector. and ``state``\n",
      "        is an `OptimizeResult` object, with the same fields\n",
      "        as the ones from the return.  If callback returns True\n",
      "        the algorithm execution is terminated.\n",
      "        For all the other methods, the signature is:\n",
      "    \n",
      "            ``callback(xk)``\n",
      "    \n",
      "        where ``xk`` is the current parameter vector.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        The optimization result represented as a ``OptimizeResult`` object.\n",
      "        Important attributes are: ``x`` the solution array, ``success`` a\n",
      "        Boolean flag indicating if the optimizer exited successfully and\n",
      "        ``message`` which describes the cause of the termination. See\n",
      "        `OptimizeResult` for a description of other attributes.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    minimize_scalar : Interface to minimization algorithms for scalar\n",
      "        univariate functions\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method is *BFGS*.\n",
      "    \n",
      "    **Unconstrained minimization**\n",
      "    \n",
      "    Method :ref:`Nelder-Mead <optimize.minimize-neldermead>` uses the\n",
      "    Simplex algorithm [1]_, [2]_. This algorithm is robust in many\n",
      "    applications. However, if numerical computation of derivative can be\n",
      "    trusted, other algorithms using the first and/or second derivatives\n",
      "    information might be preferred for their better performance in\n",
      "    general.\n",
      "    \n",
      "    Method :ref:`Powell <optimize.minimize-powell>` is a modification\n",
      "    of Powell's method [3]_, [4]_ which is a conjugate direction\n",
      "    method. It performs sequential one-dimensional minimizations along\n",
      "    each vector of the directions set (`direc` field in `options` and\n",
      "    `info`), which is updated at each iteration of the main\n",
      "    minimization loop. The function need not be differentiable, and no\n",
      "    derivatives are taken.\n",
      "    \n",
      "    Method :ref:`CG <optimize.minimize-cg>` uses a nonlinear conjugate\n",
      "    gradient algorithm by Polak and Ribiere, a variant of the\n",
      "    Fletcher-Reeves method described in [5]_ pp.  120-122. Only the\n",
      "    first derivatives are used.\n",
      "    \n",
      "    Method :ref:`BFGS <optimize.minimize-bfgs>` uses the quasi-Newton\n",
      "    method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5]_\n",
      "    pp. 136. It uses the first derivatives only. BFGS has proven good\n",
      "    performance even for non-smooth optimizations. This method also\n",
      "    returns an approximation of the Hessian inverse, stored as\n",
      "    `hess_inv` in the OptimizeResult object.\n",
      "    \n",
      "    Method :ref:`Newton-CG <optimize.minimize-newtoncg>` uses a\n",
      "    Newton-CG algorithm [5]_ pp. 168 (also known as the truncated\n",
      "    Newton method). It uses a CG method to the compute the search\n",
      "    direction. See also *TNC* method for a box-constrained\n",
      "    minimization with a similar algorithm. Suitable for large-scale\n",
      "    problems.\n",
      "    \n",
      "    Method :ref:`dogleg <optimize.minimize-dogleg>` uses the dog-leg\n",
      "    trust-region algorithm [5]_ for unconstrained minimization. This\n",
      "    algorithm requires the gradient and Hessian; furthermore the\n",
      "    Hessian is required to be positive definite.\n",
      "    \n",
      "    Method :ref:`trust-ncg <optimize.minimize-trustncg>` uses the\n",
      "    Newton conjugate gradient trust-region algorithm [5]_ for\n",
      "    unconstrained minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-krylov <optimize.minimize-trustkrylov>` uses\n",
      "    the Newton GLTR trust-region algorithm [14]_, [15]_ for unconstrained\n",
      "    minimization. This algorithm requires the gradient\n",
      "    and either the Hessian or a function that computes the product of\n",
      "    the Hessian with a given vector. Suitable for large-scale problems.\n",
      "    On indefinite problems it requires usually less iterations than the\n",
      "    `trust-ncg` method and is recommended for medium and large-scale problems.\n",
      "    \n",
      "    Method :ref:`trust-exact <optimize.minimize-trustexact>`\n",
      "    is a trust-region method for unconstrained minimization in which\n",
      "    quadratic subproblems are solved almost exactly [13]_. This\n",
      "    algorithm requires the gradient and the Hessian (which is\n",
      "    *not* required to be positive definite). It is, in many\n",
      "    situations, the Newton method to converge in fewer iteraction\n",
      "    and the most recommended for small and medium-size problems.\n",
      "    \n",
      "    **Bound-Constrained minimization**\n",
      "    \n",
      "    Method :ref:`L-BFGS-B <optimize.minimize-lbfgsb>` uses the L-BFGS-B\n",
      "    algorithm [6]_, [7]_ for bound constrained minimization.\n",
      "    \n",
      "    Method :ref:`TNC <optimize.minimize-tnc>` uses a truncated Newton\n",
      "    algorithm [5]_, [8]_ to minimize a function with variables subject\n",
      "    to bounds. This algorithm uses gradient information; it is also\n",
      "    called Newton Conjugate-Gradient. It differs from the *Newton-CG*\n",
      "    method described above as it wraps a C implementation and allows\n",
      "    each variable to be given upper and lower bounds.\n",
      "    \n",
      "    **Constrained Minimization**\n",
      "    \n",
      "    Method :ref:`COBYLA <optimize.minimize-cobyla>` uses the\n",
      "    Constrained Optimization BY Linear Approximation (COBYLA) method\n",
      "    [9]_, [10]_, [11]_. The algorithm is based on linear\n",
      "    approximations to the objective function and each constraint. The\n",
      "    method wraps a FORTRAN implementation of the algorithm. The\n",
      "    constraints functions 'fun' may return either a single number\n",
      "    or an array or list of numbers.\n",
      "    \n",
      "    Method :ref:`SLSQP <optimize.minimize-slsqp>` uses Sequential\n",
      "    Least SQuares Programming to minimize a function of several\n",
      "    variables with any combination of bounds, equality and inequality\n",
      "    constraints. The method wraps the SLSQP Optimization subroutine\n",
      "    originally implemented by Dieter Kraft [12]_. Note that the\n",
      "    wrapper handles infinite values in bounds by converting them into\n",
      "    large floating values.\n",
      "    \n",
      "    Method :ref:`trust-constr <optimize.minimize-trustconstr>` is a\n",
      "    trust-region algorithm for constrained optimization. It swiches\n",
      "    between two implementations depending on the problem definition.\n",
      "    It is the most versatile constrained minimization algorithm\n",
      "    implemented in SciPy and the most appropriate for large-scale problems.\n",
      "    For equality constrained problems it is an implementation of Byrd-Omojokun\n",
      "    Trust-Region SQP method described in [17]_ and in [5]_, p. 549. When\n",
      "    inequality constraints  are imposed as well, it swiches to the trust-region\n",
      "    interior point  method described in [16]_. This interior point algorithm,\n",
      "    in turn, solves inequality constraints by introducing slack variables\n",
      "    and solving a sequence of equality-constrained barrier problems\n",
      "    for progressively smaller values of the barrier parameter.\n",
      "    The previously described equality constrained SQP method is\n",
      "    used to solve the subproblems with increasing levels of accuracy\n",
      "    as the iterate gets closer to a solution.\n",
      "    \n",
      "    **Finite-Difference Options**\n",
      "    \n",
      "    For Method :ref:`trust-constr <optimize.minimize-trustconstr>`\n",
      "    the gradient and the Hessian may be approximated using\n",
      "    three finite-difference schemes: {'2-point', '3-point', 'cs'}.\n",
      "    The scheme 'cs' is, potentially, the most accurate but it\n",
      "    requires the function to correctly handles complex inputs and to\n",
      "    be differentiable in the complex plane. The scheme '3-point' is more\n",
      "    accurate than '2-point' but requires twice as much operations.\n",
      "    \n",
      "    **Custom minimizers**\n",
      "    \n",
      "    It may be useful to pass a custom minimization method, for example\n",
      "    when using a frontend to this method such as `scipy.optimize.basinhopping`\n",
      "    or a different library.  You can simply pass a callable as the ``method``\n",
      "    parameter.\n",
      "    \n",
      "    The callable is called as ``method(fun, x0, args, **kwargs, **options)``\n",
      "    where ``kwargs`` corresponds to any other parameters passed to `minimize`\n",
      "    (such as `callback`, `hess`, etc.), except the `options` dict, which has\n",
      "    its contents also passed as `method` parameters pair by pair.  Also, if\n",
      "    `jac` has been passed as a bool type, `jac` and `fun` are mangled so that\n",
      "    `fun` returns just the function values and `jac` is converted to a function\n",
      "    returning the Jacobian.  The method shall return an `OptimizeResult`\n",
      "    object.\n",
      "    \n",
      "    The provided `method` callable must be able to accept (and possibly ignore)\n",
      "    arbitrary parameters; the set of parameters accepted by `minimize` may\n",
      "    expand in future versions and then these parameters will be passed to\n",
      "    the method.  You can find an example in the scipy.optimize tutorial.\n",
      "    \n",
      "    .. versionadded:: 0.11.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Nelder, J A, and R Mead. 1965. A Simplex Method for Function\n",
      "        Minimization. The Computer Journal 7: 308-13.\n",
      "    .. [2] Wright M H. 1996. Direct search methods: Once scorned, now\n",
      "        respectable, in Numerical Analysis 1995: Proceedings of the 1995\n",
      "        Dundee Biennial Conference in Numerical Analysis (Eds. D F\n",
      "        Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.\n",
      "        191-208.\n",
      "    .. [3] Powell, M J D. 1964. An efficient method for finding the minimum of\n",
      "       a function of several variables without calculating derivatives. The\n",
      "       Computer Journal 7: 155-162.\n",
      "    .. [4] Press W, S A Teukolsky, W T Vetterling and B P Flannery.\n",
      "       Numerical Recipes (any edition), Cambridge University Press.\n",
      "    .. [5] Nocedal, J, and S J Wright. 2006. Numerical Optimization.\n",
      "       Springer New York.\n",
      "    .. [6] Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory\n",
      "       Algorithm for Bound Constrained Optimization. SIAM Journal on\n",
      "       Scientific and Statistical Computing 16 (5): 1190-1208.\n",
      "    .. [7] Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm\n",
      "       778: L-BFGS-B, FORTRAN routines for large scale bound constrained\n",
      "       optimization. ACM Transactions on Mathematical Software 23 (4):\n",
      "       550-560.\n",
      "    .. [8] Nash, S G. Newton-Type Minimization Via the Lanczos Method.\n",
      "       1984. SIAM Journal of Numerical Analysis 21: 770-778.\n",
      "    .. [9] Powell, M J D. A direct search optimization method that models\n",
      "       the objective and constraint functions by linear interpolation.\n",
      "       1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez\n",
      "       and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.\n",
      "    .. [10] Powell M J D. Direct search algorithms for optimization\n",
      "       calculations. 1998. Acta Numerica 7: 287-336.\n",
      "    .. [11] Powell M J D. A view of algorithms for optimization without\n",
      "       derivatives. 2007.Cambridge University Technical Report DAMTP\n",
      "       2007/NA03\n",
      "    .. [12] Kraft, D. A software package for sequential quadratic\n",
      "       programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace\n",
      "       Center -- Institute for Flight Mechanics, Koln, Germany.\n",
      "    .. [13] Conn, A. R., Gould, N. I., and Toint, P. L.\n",
      "       Trust region methods. 2000. Siam. pp. 169-200.\n",
      "    .. [14] F. Lenders, C. Kirches, A. Potschka: \"trlib: A vector-free\n",
      "       implementation of the GLTR method for iterative solution of\n",
      "       the trust region problem\", https://arxiv.org/abs/1611.04718\n",
      "    .. [15] N. Gould, S. Lucidi, M. Roma, P. Toint: \"Solving the\n",
      "       Trust-Region Subproblem using the Lanczos Method\",\n",
      "       SIAM J. Optim., 9(2), 504--525, (1999).\n",
      "    .. [16] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. 1999.\n",
      "        An interior point algorithm for large-scale nonlinear  programming.\n",
      "        SIAM Journal on Optimization 9.4: 877-900.\n",
      "    .. [17] Lalee, Marucha, Jorge Nocedal, and Todd Plantega. 1998. On the\n",
      "        implementation of an algorithm for large-scale equality constrained\n",
      "        optimization. SIAM Journal on Optimization 8.3: 682-706.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Let us consider the problem of minimizing the Rosenbrock function. This\n",
      "    function (and its respective derivatives) is implemented in `rosen`\n",
      "    (resp. `rosen_der`, `rosen_hess`) in the `scipy.optimize`.\n",
      "    \n",
      "    >>> from scipy.optimize import minimize, rosen, rosen_der\n",
      "    \n",
      "    A simple application of the *Nelder-Mead* method is:\n",
      "    \n",
      "    >>> x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
      "    >>> res = minimize(rosen, x0, method='Nelder-Mead', tol=1e-6)\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    \n",
      "    Now using the *BFGS* algorithm, using the first derivative and a few\n",
      "    options:\n",
      "    \n",
      "    >>> res = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n",
      "    ...                options={'gtol': 1e-6, 'disp': True})\n",
      "    Optimization terminated successfully.\n",
      "             Current function value: 0.000000\n",
      "             Iterations: 26\n",
      "             Function evaluations: 31\n",
      "             Gradient evaluations: 31\n",
      "    >>> res.x\n",
      "    array([ 1.,  1.,  1.,  1.,  1.])\n",
      "    >>> print(res.message)\n",
      "    Optimization terminated successfully.\n",
      "    >>> res.hess_inv\n",
      "    array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary\n",
      "           [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],\n",
      "           [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],\n",
      "           [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],\n",
      "           [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])\n",
      "    \n",
      "    \n",
      "    Next, consider a minimization problem with several constraints (namely\n",
      "    Example 16.4 from [5]_). The objective function is:\n",
      "    \n",
      "    >>> fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
      "    \n",
      "    There are three constraints defined as:\n",
      "    \n",
      "    >>> cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
      "    ...         {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
      "    \n",
      "    And variables must be positive, hence the following bounds:\n",
      "    \n",
      "    >>> bnds = ((0, None), (0, None))\n",
      "    \n",
      "    The optimization problem is solved using the SLSQP method as:\n",
      "    \n",
      "    >>> res = minimize(fun, (2, 0), method='SLSQP', bounds=bnds,\n",
      "    ...                constraints=cons)\n",
      "    \n",
      "    It should converge to the theoretical solution (1.4 ,1.7).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(optimize.minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
